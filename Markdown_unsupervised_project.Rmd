---
title: "Unsupervised project: IQ test"
author: "Tommaso Locatelli"
date: "11/11/2021"
output: pdf_document
abstract: "In this report I will apply unsupervised techniques to argue that intelligence is a multidimensional skill that can hardly be classified with just one number. Analyzing the scores obtained in an IQ test, first with clustering techniques I will identify groups of people with different performances depending on the type of ability tested by the questions. Secondly, I will bring out several concepts of intelligence from principal component analysis."
---

# Research question and dataset

The key idea of an IQ test is that there is some sort of total order relationship between people's intelligence. Thanks to this assumption, it seems sensible to associate a number with each person's performance so that the higher the intelligence, the higher the score. The aim of this analysis is to demonstrate how this approach is at least reductive since intelligence, as a complex concept, cannot be considered a one-dimensional but a multidimensional characteristic. By this I mean that depending on specific tasks, different people can perform better in one but not the other. To do this I intend to analyze a database available on Kaggle ( [linked phrase](https://www.kaggle.com/lucasgreenwell/alphaversion-fullscale-iq-test-responses?select=codebook.txt) ) that collects the answers to an IQ test.

```{r, include=FALSE}
library(dplyr)
library(tidyverse)
library("scatterplot3d")
library(wesanderson)

data <- read.csv("C:/Users/tomma/Desktop/Salini projects/Unsupervised/data.csv")
```

The IQ test consisted of: seven vocabulary test questions, six mental rotations and six short-term memory questions. Each question had eight possible answers of which three to five were correct. Each correct answer equals +1 while each incorrect answer -1. Each question is coded according to the type of question (VQ stands for vocabulary question, RQ for rotation question and MQ for memory question) and the number of the question. Furthermore, for each question it is reported: the score (s), the answers (a) and the elapsed time in milliseconds (e). Other values were also recorded: 

1. introelapse	time spent on the landing page in seconds

2. testelapse	time spent on the test page in seconds

3. endelapse	time spent on the page where they agreed to donate their data

Here is an example of some values from the first observations

```{r, echo=FALSE}
head(data[c(1,2,3,22,40,59,60,61)])
```

In this project we will only be interested in the scores obtained in the questions, so we get rid of all the remaining columns and calculate the partial sums by type of question and the total sum of the score.

```{r, echo=FALSE}
data_points=data[c(seq(1,56,3))]
data_points <-  data_points %>%
  add_column(VQt = rowSums(.[1:7]),
             RQt = rowSums(.[8:13]),
             MQt = rowSums(.[14:19]))
data_points <-  data_points %>%
  add_column(IQ = rowSums(.[20:22]))
head(data_points, n=3L)
```

VQt means vocubulary question's total, RQt rotational question's total and MQt memory question's total; the IQ is the total sum.

In light of the division into sections of the test we will try to highlight how people can be divided into different types of intelligence rather than one-dimensional degrees of intelligence. For the sake of simplicity we will refer to a one-dimensional view of intelligence as a _traditional paradigm_ and to a multidimensional view of intelligence as a _paradigm of heterogeneity_.

\newpage

# Data desciption

Before starting the analysis let's look at the distribution of the total scores and in the different sections.

```{r, echo=FALSE, fig.height = 3, fig.width = 3}
hist(data_points$IQ)
hist(data_points$VQt)
hist(data_points$RQt)
hist(data_points$MQt)
```

We can make the first observations starting from the histograms and the summary of the different columns:

1. the scores seem more concentrated in the memory questions than the others

2. the average score per question varies between questions, this can be interpreted as having more difficult questions and easier questions

3. there are outliers in the left-hand tail, those who have obtained highly negative final scores

4. if for each question you take the best answer that someone gave you get a score of 81, we don't know what the real total score was

```{r, echo=FALSE}
summary(data_points)
```
\newpage

# Cluster analysis

Before proceeding with the cluster analysis it is useful to clarify which results we expect might confirm the _traditional paradigm_ or the _heterogeneity paradigm_.
So that the data will confirm the _traditional paradigm_ if they let identify clusters with a increasing total and partial score in each section, while the data will confirm the _heterogeneity paradigm_ if different clusters will perform better or lower than others depending on the section considered.

## Complete hierarchical clustering

Let's start with hierarchical clustering using the complete method.
We arbitrarily choose to cut the tree to 5 clusters because a larger number would make interpretation difficult for our problem and a smaller number would not bring out enough interest groups.

```{r, echo=FALSE, fig.height = 3, fig.width = 3}
h1=hclust(dist(data_points[-c(20,21,22,23)]),method="complete") #euclidean distance by default
#plot(h1)
complete=cutree(h1, k=5)
```

From the plots it is possible to understand that the clusters obtained are in a certain sense intermediate between the previously hypothesized cases.
Although there is a general degree of overall improvement in performance from cluster to cluster it appears that some have areas of strengths and weaknesses.

```{r, echo=FALSE, fig.height = 3.7, fig.width = 3.7}
colors <- c('green', 'red','yellow','blue','black')[unclass(complete)]
pairs(~RQt+MQt+VQt,data=data_points, col=colors)
scatterplot3d(data_points[,20:22], angle = 45, color=colors)
```

```{r, echo=FALSE}
medie1<-aggregate(data_points, list(complete), mean)
medie1[c(21,22,23,24)]
write.table(medie1[c(21,22,23,24)])
count1<-aggregate(data_points, list(complete), FUN = length)
#count1[c(24)]
```
The first cluster is fine in all but stands out especially for excelling in rotations over the others, the second is distinguished from the first only by a low score in rotations, the third worsens slightly in rotation but drops dramatically in vocabulary, the last two fall in turn in all sectors but represent relatively small clusters and with relatively isolated points with respect to the others.

## Average hierarchical clustering

We proceed by repeating the same analysis but using the average method.

```{r, echo=FALSE, fig.height = 3.7, fig.width = 3.7}
h2=hclust(dist(data_points[-c(20,21,22,23)]),method="average") #euclidean distance by default
#plot(h1)
average=cutree(h2, k=7)
colors2 <- c('green', 'red','yellow','blue','black','brown','pink')[unclass(average)]
pairs(~RQt+MQt+VQt,data=data_points, col=colors2)
scatterplot3d(data_points[,20:22], angle = 45, color=colors2)
```

```{r, echo=FALSE}
medie2<-aggregate(data_points, list(average), mean)
medie2[c(21,22,23,24)]
write.table(medie2[c(21,22,23,24)])
count2<-aggregate(data_points, list(average), FUN = length)
names(count2)[c(24)] <- 'Count:'
count2[c(24)]
```
This time it seems that most of the points collapse in the same cluster and put small sets of isolated data in the others making the division useless.

## Ward hierarchical clustering

The last choice we will evaluate for hierarchical clustering is the Ward method which, trivially speaking, makes the outliers count less.

```{r, echo=FALSE, fig.height = 3.7, fig.width = 3.7}
h4=hclust(dist(data_points[-c(20,21,22,23)]),method="ward.D2") # forcing to include outliers
#plot(h1)
ward=cutree(h4, k=5)
```

```{r, echo=FALSE, fig.height = 3.9, fig.width = 3.9}
colors <- c('green', 'red','yellow','blue','black')[unclass(ward)]
pairs(~RQt+MQt+VQt,data=data_points, col=colors)
scatterplot3d(data_points[,20:22], angle = 45, color=colors)
```

```{r, echo=FALSE}
medie4<-aggregate(data_points, list(ward), mean)
medie4[c(21,22,23,24)]
write.table(medie4[c(21,22,23,24)])
count4<-aggregate(data_points, list(ward), FUN = length)
#count4[c(24)]
```

The results are consistent with what has been found so far: the cluster that achieves the best average score is good in all sections, the second loses points in the rotations, the third in the vocabulary, the fourth very bad in the rotation and thank goodness in the vocabulary and the last in all but memory.

## K-means

Finally we try to apply k-means to find the clusters.

```{r, echo=FALSE, fig.height = 3.7, fig.width = 3.7}
fit <- kmeans(data_points, 5) # 4 cluster solution
colors <- c('green', 'red','yellow','blue','black')[unclass(fit$cluster)]
pairs(~RQt+MQt+VQt,data=data_points, col=colors)
scatterplot3d(data_points[,20:22], angle = 45, color=colors)
medie3=aggregate(data_points,by=list(fit$cluster),FUN=mean)
medie3[c(21,22,23,24)]
write.table(medie3[c(21,22,23,24)])
```

Once again the component with the highest average total score seems to do well in all sections of the test. The second group performs slightly worse in all but in reality it differs especially for the score in the rotation (consistently with the first cluster analysis). The third group seems to recover a little in the rotation but perform much worse in the vocabulary. The fourth group continues not to do badly if it were not for a bad result in the rotations. Finally the last group is worse in everything without lowering too much the score in the memory.

As in the first and third cases, the presence of the best group and the worst group seems to support the _traditional paradigm_ while the presence of intermediate groups that are distinguished by preference in the sections is in favor of the _heterogeneity paradigm_.

## Which questions are most significant?

We will use the clusters obtained with the ward method because they are the ones that have a greater interpretability in the plots.

```{r, echo=FALSE}
##### calculate R^2
mydata<-data_points[-c(20,21,22,23)]
mydata$group<-complete #choose the cluster
R2 <- rep(NA, (ncol(mydata)-1))
for(i in 1:(ncol(mydata)-1)) 
  R2[i] <- anova(aov(mydata[,i] ~ mydata[,ncol(mydata)]))[1,2]/(anova(aov(mydata[,i] ~ mydata[,ncol(mydata)]))[1,2]+anova(aov(mydata[,i] ~ mydata[,ncol(mydata)]))[2,2])
mydata<-mydata[,-ncol(mydata)]
col<-colnames(mydata)
finali<-cbind(col,R2)
finali
```
Coherently with the fact that the scores in the memory section are more concentrated and with the fact that it is the characteristic that changes less between clusters, $r^2$ associated with the related questions turn out to be smaller than 0.1 unlike the values associated with the questions of the other two sections. In general, a question's $r ^ 2$ can be interpreted as its power to discern between peopleintelligence. Questions with a low value were either too easy or too difficult.

\newpage

# PCA

Up to this point the cluster analysis seems to have confirmed what this project tries to argue, in order to have a deeper point of view on the issue we also proceed with the principal component analysis.

The explain variance of each component is:
```{r, echo=FALSE}
n <- nrow(data_points[-c(20,21,22,23)])
p <- ncol(data_points[-c(20,21,22,23)])
rho <- cor(data_points[-c(20,21,22,23)])
autoval <- eigen(rho)$values
autovec <- eigen(rho)$vectors

# Select components
pvarsp = autoval/p
pvarspcum = cumsum(pvarsp)
pvarsp
```
The result is quite bad, from the mono-dimensional ranking point of view, because there are no components with a high value, this probably depends also on the large number of variables. Despite this, the first three can explain about 50% of the variance.

```{r, echo=FALSE, fig.height = 4, fig.width = 4}
# Scree Diagram:
plot(autoval, type="b", main="Scree Diagram", xlab="Components", ylab="Eigenvalue")
abline(h=1, lwd=3, col="red")
```

We can see how the first 4 have an eigenvalue greater than one.

```{r, echo=FALSE}
medie <- colMeans(data_points[-c(20,21,22,23)])
scarto <- apply(data_points[-c(20,21,22,23)], 2, sd)
descrittive<-round(cbind(medie, scarto),2)
comp<-round(cbind(-eigen(rho)$vectors[,1]*sqrt(autoval[1]),-eigen(rho)$vectors[,2]*sqrt(autoval[2]),-eigen(rho)$vectors[,3]*sqrt(autoval[3]),-eigen(rho)$vectors[,4]*sqrt(autoval[4])),3)
rownames(comp)<-row.names(descrittive)
colnames(comp)<-c("Comp1","Comp2","Comp3","Comp4")
```
Looking at these components it seems that the analysis is positive all in all for the thesis of this project. 
Although the first component is positively linked to each question, which makes it interpreted as a sort of degree of general intelligence, but the low variance explained by it show that is not really easy to rank only on one dimension. It is also true that have larger coefficient in the rotation question, so probably is also linked with a sort of mathematical intelligence.

The second and third also have a behavior very favorable to the _paradigm of heterogeneity_.
The second component assigns positive values only to questions related to the vocabulary, we could therefore interpret it as a linguistic or verbal intelligence. While the third associates negative values mainly only with questions related to rotation, this could be interpreted as a negation of logical-mathematical intelligence. Having no other information on the content of the questions it is difficult to interpret the fourth component.

```{r, echo=FALSE}
comunalita<-comp[,1]^2+comp[,2]^2+comp[,3]^2+comp[,4]^2
comp<-cbind(comp,comunalita)
write.table(comp)
```
It seems that low comunalities are associated with some questions, it may be link to low variance which could lead us to consider them also as less significant.

```{r, echo=FALSE, fig.height = 4, fig.width = 4}
# scores:
oecd=data_points[-c(20,21,22,23)]
oecd.scale <- scale(oecd, T, T)
punteggi <- oecd.scale%*%autovec[,1:2]
# standardized scores
punteggiz<-round(cbind(-punteggi[,1]/sqrt(autoval[1]),-punteggi[,2]/sqrt(autoval[2])),2)
plot(punteggiz, main="Score plot",
     xlab="comp1",ylab="comp2")
abline(v=0,h=0,col="red")
```

Now we can see, in the score plot, pretty well how the data are far from being crushed just on one dimension.

```{r, echo=FALSE, fig.height = 4, fig.width = 4}
# loadinngs
plot(comp[,1:2], main="Loadings plot",
     xlab="comp1",ylab="comp2", xlim=range(-1,1))
text(comp, rownames(comp))
abline(v=0,h=0,col="red")
```

Furthermore, the loads seem to group according to the type of question.
Therefore the observers belonging to the second and fourth quadrant of the score plot, are clearly people who, even if they have similar total scores, simply have different cognitive abilities and without being one better than the other; contradicting the _traditional paradigm_.

\newpage

# Conclusion

Given the high interpretability and consistency of the distribution of scores in each section between the clusters found, the low variance explained by the main component and the match between components and types of questions, this report claims to be largely successful in its goal, that is to highlight how intelligence cannot be considered a one-dimensional characteristic.
In particular, the data showed that according to the type of questions different people find themselves answering better or worse than others; as for example, a good verbal intelligence does not also involve a good logical-mathematical intelligence and vice versa.
In light of this, the value of the IQ tests should be reconsidered not in the mere final score but in the range of different cognitive areas. For example, it might be valuable to add still different types of questions to allow those with other qualities to demonstrate it.
A final consideration is that not all available information has been used in this project. It would be interesting to use the columns relating to the elapsed times to evaluate whether who performs best takes even less time to answer or if speed is a characteristic independent from general intelligence.
Or through a study with association rules to understand if there are ways of thinking shared between groups that lead them not only to similar scores but also to similar correct answers and errors.

\newpage

# Appendix

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```