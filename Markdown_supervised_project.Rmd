---
title: 'Supervised project: Cardiovascular disease'
author: "Tommaso Locatelli"
date: "11/11/2021"
output: pdf_document
abstract: "In this report I will analyze the risk factors of cardiovascular disease starting from a dataset that includes different types of features. Using logistic regressions in different ways, I will have to deal with various problems related to confounding effects which, once identified, I will show that they are sensitive to being eliminated by a penalized logistic regression."
---

# Research question and dataset

The aim of this project is to analyze risk factors for heart disease starting from the Cardiovascular Disease dataset available on Kaggle ( [linked phrase](https://www.kaggle.com/sulianova/cardiovascular-disease-dataset?select=cardio_train.csv) ).
According to the World Health Organization the most important behavioural risk factors of heart disease are unhealthy diet, physical inactivity, tobacco use and harmful use of alcohol. The effects of behavioural risk factors may show up in individuals as raised blood pressure, raised blood glucose, raised blood lipids, and overweight and obesity. This work will focus on verifying these risk factors and evaluating others according to the variables available in the dataset. In particular, it will be of interest not the accuracy of the prediction but the inference of a relationship between disease and factors.

First we load the dataset, drop the id and start loocking at it.

```{r, echo=FALSE}
cardio_train <- read.csv("C:/Users/tomma/Desktop/Salini projects/Supervised/cardio_train.csv", sep=";")
cardio_train = subset(cardio_train, select = -c(id) )
head(cardio_train, n=3L)
```

## Legend of the variables.

There are 3 types of input features:

Objective: factual information;

Examination: results of medical examination;

Subjective: information given by the patient.

Features:

Age | Objective Feature | age | int (days)

Height | Objective Feature | height | int (cm) |

Weight | Objective Feature | weight | float (kg) |

Gender | Objective Feature | gender | categorical code | 1:Female, 2:Male

Systolic blood pressure | Examination Feature | ap_hi | int |

Diastolic blood pressure | Examination Feature | ap_lo | int |

Cholesterol | Examination Feature | cholesterol | 1: normal, 2: above normal, 3: well above normal |

Glucose | Examination Feature | gluc | 1: normal, 2: above normal, 3: well above normal |

Smoking | Subjective Feature | smoke | binary |

Alcohol intake | Subjective Feature | alco | binary |

Physical activity | Subjective Feature | active | binary |

Presence or absence of cardiovascular disease | Target Variable | cardio | binary |

All of the dataset values were collected at the moment of medical examination.

## Data cleaning and preparation

Starting from the height and weight columns we obtain the body mass index column using the formula $bmi= weight/height^2$ expressed in kg and m; we report the age in years for convenience and recode 0 as Male instead of 2 for convenience too.

```{r, include=FALSE}
library(plyr)
library(dplyr)
library(epitools)
library(caret)
library(gridExtra) 
library(tidyverse)
library(rsample)
library(e1071) 
library(GGally)
library(data.table)
library(DT)
library(readr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(corrplot)
library(rms)
library(MASS)
library(ROCR)
library(gplots)
library(pROC)
library(grid)
library(vcd)
library(ggpubr)
cardio_train$age=cardio_train$age%/%365
cardio_train = cardio_train %>% 
  mutate(bmi = weight/((height/100)^2))
cardio_train$gender[cardio_train$gender==2]=0
```

We check the dataset for abnormal values or outliers.

```{r, echo=FALSE}
summary(cardio_train)
```
Extreme not acceptable values are present in the columns: ap_hi, ap_lo. Looking at some of the abnormal registration show that there must have been some typo. 

```{r, echo=FALSE}
head(cardio_train[c(5,6)] %>% filter(ap_hi > 250))
```

Due to medical reasons we use as benchmark a minimum pressure of 40 and a maximum of 250.

```{r, echo=FALSE}
cardio_train=cardio_train[ which(cardio_train$ap_hi>40
              & cardio_train$ap_hi<250
              & cardio_train$ap_lo<250
              & cardio_train$ap_lo>40), ]
```

It seems that there are also anomalous values related to height, weight and bmi.

```{r, echo=FALSE}
head(cardio_train[c(3,4,13)] %>% filter(height < 100))
```

Some lines may have inverted weight and  height due to input errors and that cause extreme bmi values, so we cut any record with bmi bigger than 50 and lower than 10, since values lower than 16 and greater than 40 are already considered extreme.

```{r, echo=FALSE}
cardio_train=cardio_train[ which(cardio_train$bmi>10
              & cardio_train$height<240
              & cardio_train$bmi<50), ]
```

So we get our final dataset with 68519 observation and 13 variables.
```{r, echo=FALSE}
data_clean=cardio_train
data_clean$gender <- as.factor(mapvalues(data_clean$gender,
                                                 from=c("0","1"),
                                                 to=c("No", "Yes")))
data_clean$smoke <- as.factor(mapvalues(data_clean$smoke,
                                         from=c("0","1"),
                                         to=c("No", "Yes")))
data_clean$alco <- as.factor(mapvalues(data_clean$alco,
                                         from=c("0","1"),
                                         to=c("No", "Yes")))
data_clean$active <- as.factor(mapvalues(data_clean$active,
                                         from=c("0","1"),
                                         to=c("No", "Yes")))
data_clean$cardio <- as.factor(mapvalues(data_clean$cardio,
                                         from=c("0","1"),
                                         to=c("No", "Yes")))
summary(cardio_train[c(3,4,5,6,13)])
dim(cardio_train)
```
\newpage

# Data description

Let's start by seeing how our variable of interest is distributed within the database and in the various features to evaluate the balance of the sample.

```{r, echo=FALSE, fig.height = 3, fig.width = 3}
# cario distribution
p=ggplot(data_clean, aes(x = cardio)) +
  geom_bar(aes(fill = cardio)) +
  geom_text(aes(y = ..count.. -200, 
                label = paste0(round(prop.table(..count..),4) * 100, '%')), 
            stat = 'count', 
            position = position_dodge(.1), 
            size = 3)
p
```

The variable of interest is well balanced within the overall database. As regards the discrete variables, some classes are underrepresented, but the proportion of ill patients seems to grow among those with high levels of cholesterol and glucose.

```{r, echo=FALSE, fig.height = 4, fig.width = 7}
#Gender plot
p1 <- ggplot(data_clean, aes(x = gender)) +
  geom_bar(aes(fill = cardio)) +
  geom_text(aes(y = ..count.. -200, 
                label = paste0(round(prop.table(..count..),4) * 100, '%')), 
            stat = 'count', 
            position = position_dodge(.1), 
            size = 3)

#Smoke plot
p2 <- ggplot(data_clean, aes(x = smoke)) +
  geom_bar(aes(fill = cardio)) +
  geom_text(aes(y = ..count.. -200, 
                label = paste0(round(prop.table(..count..),4) * 100, '%')), 
            stat = 'count', 
            position = position_dodge(.1), 
            size = 3)

#Alco plot
p3 <- ggplot(data_clean, aes(x = alco)) +
  geom_bar(aes(fill = cardio)) +
  geom_text(aes(y = ..count.. -200, 
                label = paste0(round(prop.table(..count..),4) * 100, '%')), 
            stat = 'count', 
            position = position_dodge(.1), 
            size = 3)

#Active plot
p4 <- ggplot(data_clean, aes(x = active)) +
  geom_bar(aes(fill = cardio)) +
  geom_text(aes(y = ..count.. -200, 
                label = paste0(round(prop.table(..count..),4) * 100, '%')), 
            stat = 'count', 
            position = position_dodge(.1), 
            size = 3)

#Plot demographic data within a grid
grid.arrange(p1, p2, p3, p4, ncol=2)
```

```{r, echo=FALSE, fig.height = 4, fig.width = 7}
#Cholesterol plot
p5 <- ggplot(data_clean, aes(x = cholesterol)) +
  geom_bar(aes(fill = cardio)) +
  geom_text(aes(y = ..count.. -200, 
                label = paste0(round(prop.table(..count..),4) * 100, '%')), 
            stat = 'count', 
            position = position_dodge(.1), 
            size = 3)

#Gluc billing plot
p6 <- ggplot(data_clean, aes(x = gluc)) +
  geom_bar(aes(fill = cardio)) +
  geom_text(aes(y = ..count.. -200, 
                label = paste0(round(prop.table(..count..),4) * 100, '%')), 
            stat = 'count', 
            position = position_dodge(.1), 
            size = 3)

#Plot contract data within a grid
grid.arrange(p5, p6, ncol=1)
```

While for the continuous variables we can see how the share of sick people exceeds that of healthy ones with the increase of: age, weight, bmi and blood pressure.

```{r, echo=FALSE, fig.height = 4, fig.width = 7}
#age histogram
p7 <- ggplot(data = data_clean, aes(age, color = cardio))+
  geom_freqpoly(binwidth = 5, size = 1)

#height histogram
p8 <- ggplot(data = data_clean, aes(height, color = cardio))+
  geom_freqpoly(binwidth = 5, size = 1)

#weight charges histogram
p9 <- ggplot(data = data_clean, aes(weight, color = cardio))+
  geom_freqpoly(binwidth = 5, size = 1)

p10 <- ggplot(data = data_clean, aes(ap_hi, color = cardio))+
  geom_freqpoly(binwidth = 10, size = 1)

#ap_lo charges histogram
p11 <- ggplot(data = data_clean, aes(ap_lo, color = cardio))+
  geom_freqpoly(binwidth = 10, size = 1)

#bmi histogram
p12 <- ggplot(data = data_clean, aes(bmi, color = cardio))+
  geom_freqpoly(binwidth = 1, size = 1)

#Plot quantitative data within a grid
grid.arrange(p7, p8, p9,p10, p11, p12, ncol=2)
```

Before proceeding with the analysis it is good to check the correlation between variables through the correlation matrix and the relative p-values.

```{r, echo=FALSE, fig.height = 4, fig.width = 7}
res<-cor(cardio_train)
round(res, 2)
symnum(res, abbr.colnames = FALSE)
```

We note how in addition to trivial relationships, such as: weight and height, systolic pressure and diastolic pressure, gender and height, bmi and weight; that there are a positive and significant correlations between glucose and cholesterol, smoking and alcohol, pressures and diseases and a negative correlation between smoking and gender. Let's summarize these observations with the following plot.

```{r, echo=FALSE, fig.height = 3, fig.width = 7}
library(corrplot)
corrplot(res, type = "upper", 
         tl.col = "black", tl.srt = 45)
```

Before proceeding with the analysis it is good to point out two major limitations of this dataset: the absence of many variables related to the risk of suffering from cardiovascular diseases, such as genetic factors, diet, celiac disease, air pollution, lipid concentration in the blood and more; finally, the fact that many variables have a very small range of values, especially the subjective ones.

\newpage

# Data analysis

Before studying heart disease starting from all the features at the same time, let's take a closer look at the behavioral factors and their expressions recognized by the WHO as risky.

## Behavioral risks

Due to the absence of a variable linked to the type of diet followed we will limit ourselves to assessing smoking, alcohol consumption and inactivity. To do that we fit a logistic regression for each feature also reporting the odds ratio.

### Smoke
```{r, echo=FALSE}
lr_fits <- glm(cardio ~ smoke, data = data_clean,
          family=binomial(link='logit'))
summary(lr_fits)
exp(cbind(OR = coef(lr_fits), confint(lr_fits)))
```

### Alcohol 
```{r, echo=FALSE}
lr_fit <- glm(cardio ~ alco, data = data_clean,
          family=binomial(link='logit'))
summary(lr_fit)
exp(cbind(OR = coef(lr_fit), confint(lr_fit)))
```

### Physical activity
```{r, echo=FALSE}
lr_fit <- glm(cardio ~ active, data = data_clean,
          family=binomial(link='logit'))
summary(lr_fit)
exp(cbind(OR = coef(lr_fit), confint(lr_fit)))
```

Contrary to our expectations, logistic regression seems to point to smoke and alco as protective factors of the disease. In the case of smoking even with a good significance.

```{r, echo=FALSE, fig.height = 3, fig.width = 4}
smoke_table <- xtabs(~smoke+cardio, data=data_clean)
alco_table <- xtabs(~alco+cardio, data=data_clean)
plot(smoke_table , col=c("tomato","skyblue3"))
```

We note that the proportion of sick people is actually slightly lower among smokers, a similar situation is also found in alcohol users since the two variables are positively correlated. We can also check it numerically with the proportional crosstabs that show how the percentage of ill patients decrease in the smoking class.

```{r, echo=FALSE}
prop.table(smoke_table, 1) 
prop.table(alco_table, 1) 
```
Finally we can check the indipendence of the two classes with the Chi-squared test.

```{r, echo=FALSE}
Test <- chisq.test(smoke_table, correct=FALSE)
Test

Test <- chisq.test(alco_table, correct=FALSE)
Test
```

In both cases we find a significant difference from the independence, especially for the smoke variable.
All these considerations leads us to consider the possibility of finding ourselves in front of a confounding effect. Perhaps a third variable influences both the presence of heart disease and our explanatory variables causing a spurious association.

```{r, echo=FALSE, fig.height = 5, fig.width = 7}
library(vcd)
hec2 <- structable(cardio ~  age + smoke , data = data_clean)

mosaic(hec2, split_vertical = c(TRUE, FALSE, FALSE),
       labeling_args = list(abbreviate = c(Eye = 3)))
```

Through a mosaic graph that shows the distribution of patients and smokers according to age, it is possible to hypothesize that age is a determining factor for heart problems while the proportion of smokers decreased, this could induce the observed spurious relationship.

```{r, echo=FALSE, fig.height = 3.5, fig.width = 2}
boxplot(data_clean$age ~ data_clean$smoke)
boxplot(data_clean$age ~ data_clean$alco)
boxplot(data_clean$age ~ data_clean$cardio)
```

Coherently we find that smokers and alcohol users are on average younger while the sick are often the oldest.

Let's check the hypothesis that probability of cardiovascualar disease increase due to the age and also that probability of to be a smoker decrease with increasing age through two other logistic regressions.

### Age
```{r, echo=FALSE}
lr_fita <- glm(cardio ~ age, data = data_clean,
          family=binomial(link='logit'))
summary(lr_fita)
```

### Smoke prediction with respect to age
```{r, echo=FALSE}
lr_fit <- glm(smoke ~ age, data = data_clean,
          family=binomial(link='logit'))
summary(lr_fit)
```

## Expression of risks in medical examination

Let's look at the examination features and bmi as WHO considers them symptoms of a high risk of heart disease. We note, however, that the concentration of lipids in the blood is not present.

### Blood pressure
```{r, echo=FALSE}
lr_fit <- glm(cardio ~ ap_hi + ap_lo, data = data_clean,
          family=binomial(link='logit'))
summary(lr_fit)
```

### Cholesterol
```{r, echo=FALSE}
lr_fit <- glm(cardio ~ cholesterol, data = data_clean,
          family=binomial(link='logit'))
summary(lr_fit)
```

### Glucose
```{r, echo=FALSE}
lr_fit <- glm(cardio ~ gluc, data = data_clean,
          family=binomial(link='logit'))
summary(lr_fit)
```

### Bmi
```{r, echo=FALSE}
lr_fit <- glm(cardio ~ bmi, data = data_clean,
          family=binomial(link='logit'))
summary(lr_fit)
```

This time we get the coefficients we expected and in all cases they turn out to be significant.

## Attempts to build a multiple model

At this point it would be interesting to build a model that takes into account several variables at the same time and if possible to avoid problems of confounding effect. 

### Total multiple model

As a first approach we try to construct a multiple logistic model that takes into account all the available variables parameterizing it starting from a training set and judging its performance in the test set.

```{r, echo=FALSE}
#Train and test
set.seed(1) #1,40,41,42
split_train_test <- createDataPartition(data_clean$cardio,p=0.7,list=FALSE)
dtrain<- data_clean[split_train_test,]
dtest<-  data_clean[-split_train_test,]

#logistic regression
lr_fit <- glm(cardio ~., data = dtrain[-c(3,4)],
              family=binomial(link='logit'))
summary(lr_fit)
```

Regarding the fit of the model several things should be noted:

1. almost any coefficient is significant

2. the glucose is now considered a protective factor

3. alcohol and smoke are considered as risk factors anyway

4. gender is correctly recognized as a protective factor as we know that incidence of CVD in women is usually lower than in men (despite the low significance)

5. we excluded height and weight as it would have suffered from high collinearity with the bmi



Performance in the training set:

```{r, echo=FALSE}
lr_prob1 <- predict(lr_fit, dtest, type="response")
lr_pred1 <- ifelse(lr_prob1 > 0.5,"Yes","No")
lr_prob2 <- predict(lr_fit, dtrain, type="response")
lr_pred2 <- ifelse(lr_prob2 > 0.5,"Yes","No")
lr_tab1 <- table(Predicted = lr_pred2, Actual = dtrain$cardio)
lr_tab2 <- table(Predicted = lr_pred1, Actual = dtest$cardio)
#train
confusionMatrix(
  as.factor(lr_pred2),
  as.factor(dtrain$cardio),
  positive = "Yes" 
)
```
Performance in the test set:
```{r, echo=FALSE}
#test
confusionMatrix(
  as.factor(lr_pred1),
  as.factor(dtest$cardio),
  positive = "Yes" 
)
```
It is important to note that the sensitivity is quite low in both cases

ROC curve:

```{r, echo=FALSE}
#ROC, sensitivity TP, 1-specificity FP
lr_prob2 <- predict(lr_fit, dtest, type="response")
test_roc = roc(dtest$cardio ~ lr_prob2, plot = TRUE, print.auc = TRUE)
```

For what concern the change in glucose sign is significant as it depends on the insertion of cholesterol, in fact, excluding the latter from the regression, the glucose coefficient returns to being positive.

```{r, echo=FALSE}
#logistic regression
lr_fit <- glm(cardio ~., data = dtrain[-c(3,4,7)],
              family=binomial(link='logit'))
summary(lr_fit)
```

This could be linked to the fact that both glucose and cholesterol, in addition to being important risk factors, are also generally higher among women which instead is a protective factor.

```{r, echo=FALSE}
hec4 <- structable(gluc~ gender, data = data_clean)
mosaic(hec4, split_vertical = c(T,F),
       labeling_args = list(abbreviate = c(Eye = 3)))
```

Finally, it is worth to evaluate the collinearity between the latter.

VIF for collinearity:

```{r, echo=FALSE}
#vif for collinearity
vif(lr_fit)
```
But as can be seen there are no significantly high values and the two maxima related to pressure are clearly induced by the deep link between these two measures.

### Lasso logistic regression

In light of the various problems that have emerged regarding the inclusion of multiple features at the same time, we apply a penalized logistic regression of the lasso type.

```{r, include=FALSE}
# Split the data into training and test set
set.seed(123)
training.samples <- data_clean$cardio %>% 
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- data_clean[training.samples,-c(3,4) ]
test.data <- data_clean[-training.samples, -c(3,4)]

# Dumy code categorical predictor variables
x <- model.matrix(cardio~., train.data)[,-1]
# Convert the outcome (class) to a numerical variable
y <- ifelse(train.data$cardio == "Yes", 1, 0)

library(glmnet)
set.seed(123)

#fit <- glmnet(x, y)
#plot(fit, xvar = "lambda", label = TRUE)
```

```{r, echo=FALSE}
#for (i in fit$lambda){
 # if(){
  #  print(coef(fit, s = i))
  #}
#}
```

Find the optimal value of lambda that minimizes the cross-validation error:

```{r, echo=FALSE}
cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
plot(cv.lasso)
```

As can be seen from the plot, the optimal value of lambda which corresponds to the vertical dashed line on the left tends to zero and its value is:

```{r, echo=FALSE}
cv.lasso$lambda.min
```
In fact it is not surprising that no features have been excluded:

```{r, echo=FALSE}
coef(cv.lasso, cv.lasso$lambda.min)
```
Since the interest was to simplify the model rather than improve its performance let's look also the value of lambda that gives the simplest model but also lies within one standard error of the optimal value of lambda and relatives coeficients.

```{r, echo=FALSE}
cv.lasso$lambda.1se
coef(cv.lasso, cv.lasso$lambda.1se)
```
Glucose, gender and smoke were excluded probably because the weakness of the spurious relationship is somehow identified and therefore excluded by the introduction of bias that involves the increase of lambda.

\newpage

# Conclusion

Several problems have arisen in applying logistic regressions to this database, often leading to a not simple interpretation of the coefficients obtained. This could be linked to the fact that even if the database is well balanced as regards the target variable, other variables are poorly balanced between them, age and gender seem to make the proportion of other variables vary a lot, which is a fairly typical situation in observational studies like this one. In addition to this, however, it was possible to bring out the strong relationship that heart disease has with various variables, such as: cholesterol, high blood pressure and age.
An interesting final conclusion could be that the penalty due to the application of Lasso affected the coefficients that were not in line with expectations, this could be interpreted as the fact that in this case the spurious relationship induced by the confounders is less supported by the data than other risk factors.

\newpage

# Appendix

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```